{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "507ecd7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[skip] 이미 존재: /Users/leejeje/Desktop/DSL/25-1/Modeling/model/vosk-model-small-ko-0.22\n",
      "VOSK_MODEL_DIR = /Users/leejeje/Desktop/DSL/25-1/Modeling/model/vosk-model-small-ko-0.22\n"
     ]
    }
   ],
   "source": [
    "import urllib.request, zipfile, io, os\n",
    "from pathlib import Path\n",
    "\n",
    "# 저장 위치\n",
    "VOSK_MODEL_ROOT = Path(\"/Users/leejeje/Desktop/DSL/25-1/Modeling/model\")\n",
    "VOSK_MODEL_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# 한국어 소형 모델 (공식 목록에 기재된 이름)\n",
    "MODEL_URL  = \"https://alphacephei.com/vosk/models/vosk-model-small-ko-0.22.zip\"  # 공식 모델 페이지에 등재. \n",
    "TARGET_DIR = VOSK_MODEL_ROOT / \"vosk-model-small-ko-0.22\"\n",
    "\n",
    "if TARGET_DIR.exists() and any(TARGET_DIR.iterdir()):\n",
    "    print(\"[skip] 이미 존재:\", TARGET_DIR)\n",
    "else:\n",
    "    print(\"다운로드:\", MODEL_URL)\n",
    "    with urllib.request.urlopen(MODEL_URL) as resp:\n",
    "        data = resp.read()\n",
    "    with zipfile.ZipFile(io.BytesIO(data)) as zf:\n",
    "        zf.extractall(VOSK_MODEL_ROOT)\n",
    "    # 보통 zip 안에 동일한 폴더명이 들어있음\n",
    "    print(\"압축 해제 완료 →\", VOSK_MODEL_ROOT)\n",
    "    \n",
    "VOSK_MODEL_DIR = TARGET_DIR if TARGET_DIR.exists() else next(VOSK_MODEL_ROOT.glob(\"vosk-model-small-ko-0.22*\"))\n",
    "print(\"VOSK_MODEL_DIR =\", VOSK_MODEL_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ffff45cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOG (VoskAPI:ReadDataFiles():model.cc:213) Decoding params beam=10 max-active=3000 lattice-beam=2\n",
      "LOG (VoskAPI:ReadDataFiles():model.cc:216) Silence phones 1:2:3:4:5:6:7:8:9:10\n",
      "LOG (VoskAPI:RemoveOrphanNodes():nnet-nnet.cc:948) Removed 1 orphan nodes.\n",
      "LOG (VoskAPI:RemoveOrphanComponents():nnet-nnet.cc:847) Removing 2 orphan components.\n",
      "LOG (VoskAPI:Collapse():nnet-utils.cc:1488) Added 1 components, removed 2\n",
      "LOG (VoskAPI:ReadDataFiles():model.cc:248) Loading i-vector extractor from /Users/leejeje/Desktop/DSL/25-1/Modeling/model/vosk-model-small-ko-0.22/ivector/final.ie\n",
      "LOG (VoskAPI:ComputeDerivedVars():ivector-extractor.cc:183) Computing derived variables for iVector extractor\n",
      "LOG (VoskAPI:ComputeDerivedVars():ivector-extractor.cc:204) Done.\n",
      "LOG (VoskAPI:ReadDataFiles():model.cc:282) Loading HCL and G from /Users/leejeje/Desktop/DSL/25-1/Modeling/model/vosk-model-small-ko-0.22/graph/HCLr.fst /Users/leejeje/Desktop/DSL/25-1/Modeling/model/vosk-model-small-ko-0.22/graph/Gr.fst\n",
      "LOG (VoskAPI:ReadDataFiles():model.cc:303) Loading winfo /Users/leejeje/Desktop/DSL/25-1/Modeling/model/vosk-model-small-ko-0.22/graph/phones/word_boundary.int\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Vosk 모델 로드 완료: vosk-model-small-ko-0.22\n"
     ]
    }
   ],
   "source": [
    "from vosk import Model\n",
    "\n",
    "assert VOSK_MODEL_DIR.exists(), f\"모델 폴더가 없습니다: {VOSK_MODEL_DIR}\"\n",
    "vosk_model = Model(str(VOSK_MODEL_DIR))\n",
    "print(\"✅ Vosk 모델 로드 완료:\", VOSK_MODEL_DIR.name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "715710fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, soundfile as sf, json\n",
    "from vosk import KaldiRecognizer\n",
    "\n",
    "def _resample_to_16k(wave: np.ndarray, sr: int) -> np.ndarray:\n",
    "    if sr == 16000:\n",
    "        return wave.astype(\"float32\", copy=False)\n",
    "    x = np.arange(len(wave))\n",
    "    new_len = int(round(len(wave) * 16000 / sr))\n",
    "    new_x = np.linspace(0, len(wave)-1, new_len)\n",
    "    return np.interp(new_x, x, wave).astype(\"float32\")\n",
    "\n",
    "def vosk_transcribe_file(wav_path, model: Model, set_words=False, chunk_ms=50) -> str:\n",
    "    \"\"\"wav 파일을 Vosk로 인식하여 1줄 텍스트 반환\"\"\"\n",
    "    audio, sr = sf.read(str(wav_path), dtype=\"float32\", always_2d=False)\n",
    "    if audio.ndim == 2:\n",
    "        audio = audio.mean(axis=1)\n",
    "    audio = _resample_to_16k(audio, sr)  # 16k로 정규화\n",
    "    sr = 16000\n",
    "\n",
    "    # Vosk는 int16 PCM 바이트 입력을 기대 -> 변환\n",
    "    pcm16 = (np.clip(audio, -1.0, 1.0) * 32767.0).astype(np.int16)\n",
    "\n",
    "    rec = KaldiRecognizer(model, sr)\n",
    "    if set_words:\n",
    "        rec.SetWords(True)\n",
    "\n",
    "    # 50ms 단위(기본)로 스트리밍 투입\n",
    "    frames_per_chunk = int(sr * (chunk_ms / 1000.0))\n",
    "    offset = 0\n",
    "    n = len(pcm16)\n",
    "    while offset < n:\n",
    "        chunk = pcm16[offset:offset+frames_per_chunk]\n",
    "        rec.AcceptWaveform(chunk.tobytes())\n",
    "        offset += frames_per_chunk\n",
    "\n",
    "    last = json.loads(rec.FinalResult() or \"{}\")\n",
    "    return (last.get(\"text\") or \"\").strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bd785b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re, time, unicodedata, csv\n",
    "from pathlib import Path\n",
    "\n",
    "RE_BRACKETS_ALL = re.compile(r\"\\([^)]*\\)|\\[[^\\]]*\\]|\\{[^}]*\\}|<[^>]*>\")\n",
    "RE_LETTER_SLASH = re.compile(r\"(?<!\\S)[a-zA-Z]+/\\s*\")  # 'o/' 'b/' 'l/' 등 토큰 통째 제거\n",
    "RE_COLON_PREFIX = re.compile(r\"^\\s*:+\\s*\")             # 문두 ':: ' 제거\n",
    "RE_PUNCT        = re.compile(r\"[^\\w\\s]\", flags=re.UNICODE)\n",
    "RE_WS           = re.compile(r\"\\s+\")\n",
    "\n",
    "\n",
    "def u_nfc(s: str) -> str:\n",
    "    return unicodedata.normalize(\"NFC\", s)\n",
    "\n",
    "\n",
    "def normalize_for_wer(s: str) -> str:\n",
    "    s = u_nfc(s).lower()\n",
    "    s = RE_COLON_PREFIX.sub(\" \", s)       # :: 제거\n",
    "    s = RE_BRACKETS_ALL.sub(\" \", s)       # 괄호 주석 제거\n",
    "    s = RE_LETTER_SLASH.sub(\" \", s)       # 'o/' 'b/' 등 제거\n",
    "    s = RE_PUNCT.sub(\" \", s)              # 나머지 문장부호 -> 공백\n",
    "    s = RE_WS.sub(\" \", s).strip()         # 공백 정규화\n",
    "    return s\n",
    "\n",
    "def normalize_for_cer(s: str) -> str:\n",
    "    return normalize_for_wer(s).replace(\" \", \"\")\n",
    "\n",
    "def levenshtein(seq_a, seq_b):\n",
    "    n, m = len(seq_a), len(seq_b)\n",
    "    if n == 0: return m\n",
    "    if m == 0: return n\n",
    "    dp = list(range(m+1))\n",
    "    for i in range(1, n+1):\n",
    "        prev, dp[0] = dp[0], i\n",
    "        for j in range(1, m+1):\n",
    "            cur = dp[j]\n",
    "            cost = 0 if seq_a[i-1] == seq_b[j-1] else 1\n",
    "            dp[j] = min(dp[j] + 1, dp[j-1] + 1, prev + cost)\n",
    "            prev = cur\n",
    "    return dp[m]\n",
    "\n",
    "def cer_score(ref: str, hyp: str):\n",
    "    r = normalize_for_cer(ref)\n",
    "    h = normalize_for_cer(hyp)\n",
    "    if len(r) == 0: return 0.0, 0, 0\n",
    "    dist = levenshtein(r, h)\n",
    "    return dist / len(r), dist, len(r)\n",
    "\n",
    "def wer_score(ref: str, hyp: str):\n",
    "    r = normalize_for_wer(ref).split()\n",
    "    h = normalize_for_wer(hyp).split()\n",
    "    if len(r) == 0: return 0.0, 0, 0\n",
    "    dist = levenshtein(r, h)\n",
    "    return dist / len(r), dist, len(r)\n",
    "\n",
    "def load_trn(trn_path) -> dict:\n",
    "    \"\"\"\n",
    "    TRN 라인 예시 여러 형태를 모두 허용:\n",
    "      1) '문장 텍스트 ... (KsponSpeech_E00001)'\n",
    "      2) 'KsponSpeech_E00001 문장 텍스트 ...'\n",
    "      3) 'KsponSpeech_E00001.wav\\t문장 텍스트 ...'\n",
    "    반환: { 'KsponSpeech_E00001': '문장 텍스트 ...', ... }\n",
    "    \"\"\"\n",
    "    trn_path = Path(trn_path)\n",
    "    mapping = {}\n",
    "    with trn_path.open(\"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "\n",
    "            # 케이스 1) 마지막 괄호의 ID\n",
    "            m = re.search(r\"\\(([^)]+)\\)\\s*$\", line)\n",
    "            if m:\n",
    "                utt = m.group(1)\n",
    "                text = line[:m.start()].strip()\n",
    "            else:\n",
    "                # 케이스 2/3) <utt>[.wav] <sep> <text>\n",
    "                parts = re.split(r\"[\\t ]+\", line, maxsplit=1)\n",
    "                if len(parts) == 2:\n",
    "                    utt, text = parts[0], parts[1]\n",
    "                else:\n",
    "                    # 파싱 실패 시 스킵\n",
    "                    continue\n",
    "\n",
    "            utt = os.path.basename(utt)\n",
    "            utt = os.path.splitext(utt)[0]  # .wav 제거\n",
    "            mapping[utt] = text\n",
    "    return mapping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cae54143",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time, csv\n",
    "from pathlib import Path\n",
    "import soundfile as sf\n",
    "\n",
    "def evaluate_split_vosk(wav_dir, trn_path, model: Model, csv_out=None, log_every=20, preview_miss=10):\n",
    "    wav_dir  = Path(wav_dir)\n",
    "    trn_path = Path(trn_path)\n",
    "    csv_out  = Path(csv_out) if csv_out is not None else None\n",
    "\n",
    "    refs = load_trn(trn_path)\n",
    "    wavs = sorted(wav_dir.glob(\"*.wav\"))\n",
    "    print(f\"WAV: {len(wavs)} | TRN entries: {len(refs)}\")\n",
    "\n",
    "    stems = [w.stem for w in wavs]\n",
    "    missing = [s for s in stems if s not in refs]\n",
    "    if missing:\n",
    "        print(f\"[경고] TRN에서 찾을 수 없는 wav 키: {len(missing)}/{len(wavs)}개\")\n",
    "        for x in missing[:preview_miss]:\n",
    "            print(\"  -\", x)\n",
    "\n",
    "    rows = []\n",
    "    tot_cdist = tot_cN = 0\n",
    "    tot_wdist = tot_wN = 0\n",
    "    tot_secs  = tot_infer = 0.0\n",
    "\n",
    "    for i, wav in enumerate(wavs, 1):\n",
    "        utt = wav.stem\n",
    "        ref = refs.get(utt)\n",
    "        if ref is None:\n",
    "            continue\n",
    "\n",
    "        # 길이(sec)\n",
    "        audio, sr = sf.read(str(wav), dtype=\"float32\", always_2d=False)\n",
    "        dur = float(len(audio) / sr)\n",
    "\n",
    "        # 추론\n",
    "        t0 = time.perf_counter()\n",
    "        hyp = vosk_transcribe_file(wav, model, set_words=False, chunk_ms=50)\n",
    "        t1 = time.perf_counter()\n",
    "\n",
    "        infer = t1 - t0\n",
    "        rtf = infer / max(dur, 1e-9)\n",
    "\n",
    "        cer, cdist, cN = cer_score(ref, hyp)\n",
    "        wer, wdist, wN = wer_score(ref, hyp)\n",
    "\n",
    "        rows.append({\n",
    "            \"utt\": utt,\n",
    "            \"dur_s\": round(dur, 3),\n",
    "            \"infer_s\": round(infer, 3),\n",
    "            \"rtf\": round(rtf, 3),\n",
    "            \"CER\": round(cer, 4),\n",
    "            \"WER\": round(wer, 4),\n",
    "            \"ref\": ref,\n",
    "            \"hyp\": hyp,\n",
    "        })\n",
    "\n",
    "        tot_cdist += cdist; tot_cN += cN\n",
    "        tot_wdist += wdist; tot_wN += wN\n",
    "        tot_secs  += dur;   tot_infer += infer\n",
    "\n",
    "        if i % log_every == 0:\n",
    "            cum_cer = (tot_cdist/tot_cN) if tot_cN else 0.0\n",
    "            cum_wer = (tot_wdist/tot_wN) if tot_wN else 0.0\n",
    "            avg_rtf = (tot_infer/tot_secs) if tot_secs else 0.0\n",
    "            print(f\"[{i}/{len(wavs)}] RTF {rtf:.2f} | CER {cer:.3f} | WER {wer:.3f} || cum: RTF {avg_rtf:.2f}, CER {cum_cer:.3f}, WER {cum_wer:.3f}\")\n",
    "\n",
    "    if not rows:\n",
    "        print(\"\\n[중단] 매칭된 항목이 없습니다.\")\n",
    "        return {\"rows\": [], \"summary\": {\"files\": 0, \"unmatched\": len(missing)}}\n",
    "\n",
    "    overall_cer = (tot_cdist / tot_cN) if tot_cN else 0.0\n",
    "    overall_wer = (tot_wdist / tot_wN) if tot_wN else 0.0\n",
    "    avg_rtf     = (tot_infer / tot_secs) if tot_secs else 0.0\n",
    "\n",
    "    print(\"\\n=== Summary (Vosk) ===\")\n",
    "    print(f\"Files scored     : {len(rows)} (unmatched: {len(missing)})\")\n",
    "    print(f\"Total audio (s)  : {tot_secs:.1f}\")\n",
    "    print(f\"Total infer (s)  : {tot_infer:.1f}\")\n",
    "    print(f\"Avg RTF          : {avg_rtf:.3f}\")\n",
    "    print(f\"CER (char)       : {overall_cer:.4f}\")\n",
    "    print(f\"WER (word)       : {overall_wer:.4f}\")\n",
    "\n",
    "    if csv_out:\n",
    "        csv_out.parent.mkdir(parents=True, exist_ok=True)\n",
    "        fieldnames = [\"utt\",\"dur_s\",\"infer_s\",\"rtf\",\"CER\",\"WER\",\"ref\",\"hyp\"]\n",
    "        with open(csv_out, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "            w = csv.DictWriter(f, fieldnames=fieldnames)\n",
    "            w.writeheader()\n",
    "            for r in rows:\n",
    "                w.writerow(r)\n",
    "        print(f\"Saved: {csv_out}\")\n",
    "\n",
    "    rows_sorted = sorted(rows, key=lambda r: (-r[\"CER\"], -r[\"WER\"], -r[\"rtf\"]))\n",
    "    print(\"\\nTop-5 by CER:\")\n",
    "    for r in rows_sorted[:5]:\n",
    "        print(f\"- {r['utt']} | CER {r['CER']:.3f} WER {r['WER']:.3f} RTF {r['rtf']:.2f}\")\n",
    "        print(f\"  ref: {r['ref']}\")\n",
    "        print(f\"  hyp: {r['hyp']}\")\n",
    "\n",
    "    return {\n",
    "        \"rows\": rows,\n",
    "        \"summary\": dict(files=len(rows), unmatched=len(missing),\n",
    "                        total_audio_s=tot_secs, total_infer_s=tot_infer,\n",
    "                        avg_rtf=avg_rtf, cer=overall_cer, wer=overall_wer)\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2bba6fe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WAV: 3000 | TRN entries: 3000\n",
      "[경고] TRN에서 찾을 수 없는 wav 키: 19/3000개\n",
      "  - KsponSpeech_E00054\n",
      "  - KsponSpeech_E00135\n",
      "  - KsponSpeech_E00277\n",
      "  - KsponSpeech_E00511\n",
      "  - KsponSpeech_E00581\n",
      "  - KsponSpeech_E00950\n",
      "  - KsponSpeech_E01113\n",
      "  - KsponSpeech_E01343\n",
      "  - KsponSpeech_E01352\n",
      "  - KsponSpeech_E01377\n",
      "[20/3000] RTF 0.87 | CER 0.538 | WER 0.789 || cum: RTF 1.42, CER 0.602, WER 0.962\n",
      "[40/3000] RTF 1.63 | CER 0.636 | WER 1.000 || cum: RTF 1.80, CER 0.641, WER 0.947\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      4\u001b[39m trn_path = Path(\u001b[33m\"\u001b[39m\u001b[33m/Users/leejeje/Desktop/DSL/25-1/Modeling/data/KsponSpeech_scripts/eval_clean.trn\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      5\u001b[39m out_csv  = Path(\u001b[33m\"\u001b[39m\u001b[33mresults_eval\u001b[39m\u001b[33m\"\u001b[39m) / \u001b[33m\"\u001b[39m\u001b[33mvosk_eval_clean_results.csv\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m res_vosk_clean = \u001b[43mevaluate_split_vosk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwav_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrn_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvosk_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcsv_out\u001b[49m\u001b[43m=\u001b[49m\u001b[43mout_csv\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 38\u001b[39m, in \u001b[36mevaluate_split_vosk\u001b[39m\u001b[34m(wav_dir, trn_path, model, csv_out, log_every, preview_miss)\u001b[39m\n\u001b[32m     36\u001b[39m \u001b[38;5;66;03m# 추론\u001b[39;00m\n\u001b[32m     37\u001b[39m t0 = time.perf_counter()\n\u001b[32m---> \u001b[39m\u001b[32m38\u001b[39m hyp = \u001b[43mvosk_transcribe_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwav\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mset_words\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk_ms\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m50\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     39\u001b[39m t1 = time.perf_counter()\n\u001b[32m     41\u001b[39m infer = t1 - t0\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 33\u001b[39m, in \u001b[36mvosk_transcribe_file\u001b[39m\u001b[34m(wav_path, model, set_words, chunk_ms)\u001b[39m\n\u001b[32m     31\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m offset < n:\n\u001b[32m     32\u001b[39m     chunk = pcm16[offset:offset+frames_per_chunk]\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m     \u001b[43mrec\u001b[49m\u001b[43m.\u001b[49m\u001b[43mAcceptWaveform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtobytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     34\u001b[39m     offset += frames_per_chunk\n\u001b[32m     36\u001b[39m last = json.loads(rec.FinalResult() \u001b[38;5;129;01mor\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniforge/base/envs/asr-korean/lib/python3.11/site-packages/vosk/__init__.py:182\u001b[39m, in \u001b[36mKaldiRecognizer.AcceptWaveform\u001b[39m\u001b[34m(self, data)\u001b[39m\n\u001b[32m    181\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mAcceptWaveform\u001b[39m(\u001b[38;5;28mself\u001b[39m, data):\n\u001b[32m--> \u001b[39m\u001b[32m182\u001b[39m     res = \u001b[43m_c\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvosk_recognizer_accept_waveform\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    183\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m res < \u001b[32m0\u001b[39m:\n\u001b[32m    184\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mFailed to process waveform\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "wav_dir  = Path(\"/Users/leejeje/Desktop/DSL/25-1/Modeling/data/KsponSpeech_eval/eval_clean\")\n",
    "trn_path = Path(\"/Users/leejeje/Desktop/DSL/25-1/Modeling/data/KsponSpeech_scripts/eval_clean.trn\")\n",
    "out_csv  = Path(\"results_eval\") / \"vosk_eval_clean_results.csv\"\n",
    "\n",
    "res_vosk_clean = evaluate_split_vosk(wav_dir, trn_path, vosk_model, csv_out=out_csv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680574b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "asr-korean",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
