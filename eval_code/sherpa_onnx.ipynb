{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cdfbcfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re, time, unicodedata, csv\n",
    "from pathlib import Path\n",
    "\n",
    "def u_nfc(s: str) -> str:\n",
    "    return unicodedata.normalize(\"NFC\", s)\n",
    "\n",
    "# 간단 정규화: 한글 보존, 구두점 제거, 공백 정리\n",
    "_re_punct = re.compile(r\"[^\\w\\s]\", flags=re.UNICODE)\n",
    "_re_ws = re.compile(r\"\\s+\")\n",
    "\n",
    "def normalize_for_wer(s: str) -> str:\n",
    "    s = u_nfc(s).lower()\n",
    "    s = _re_punct.sub(\" \", s)\n",
    "    s = _re_ws.sub(\" \", s).strip()\n",
    "    return s\n",
    "\n",
    "def normalize_for_cer(s: str) -> str:\n",
    "    s = normalize_for_wer(s)\n",
    "    s = s.replace(\" \", \"\")\n",
    "    return s\n",
    "\n",
    "def levenshtein(seq_a, seq_b):\n",
    "    # 문자열 또는 토큰 리스트 모두 지원\n",
    "    n, m = len(seq_a), len(seq_b)\n",
    "    if n == 0: return m\n",
    "    if m == 0: return n\n",
    "    dp = list(range(m+1))\n",
    "    for i in range(1, n+1):\n",
    "        prev, dp[0] = dp[0], i\n",
    "        for j in range(1, m+1):\n",
    "            cur = dp[j]\n",
    "            cost = 0 if seq_a[i-1] == seq_b[j-1] else 1\n",
    "            dp[j] = min(dp[j] + 1, dp[j-1] + 1, prev + cost)\n",
    "            prev = cur\n",
    "    return dp[m]\n",
    "\n",
    "def cer_score(ref: str, hyp: str):\n",
    "    r = normalize_for_cer(ref)\n",
    "    h = normalize_for_cer(hyp)\n",
    "    if len(r) == 0:\n",
    "        return 0.0, 0, 0  # (CER, dist, N)\n",
    "    dist = levenshtein(r, h)\n",
    "    return dist / len(r), dist, len(r)\n",
    "\n",
    "def wer_score(ref: str, hyp: str):\n",
    "    r = normalize_for_wer(ref).split()\n",
    "    h = normalize_for_wer(hyp).split()\n",
    "    if len(r) == 0:\n",
    "        return 0.0, 0, 0\n",
    "    dist = levenshtein(r, h)\n",
    "    return dist / len(r), dist, len(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba86c8d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 모델 로드 완료\n",
      " - tokens : tokens.txt\n",
      " - encoder: encoder-epoch-99-avg-1.int8.onnx\n",
      " - decoder: decoder-epoch-99-avg-1.int8.onnx\n",
      " - joiner : joiner-epoch-99-avg-1.int8.onnx\n"
     ]
    }
   ],
   "source": [
    "import sherpa_onnx\n",
    "from pathlib import Path\n",
    "\n",
    "# 모델 폴더 지정 (네 환경 그대로 사용하거나 필요한 경로로 바꿔도 됨)\n",
    "MODEL_DIR = Path(\"/Users/leejeje/Desktop/DSL/25-1/Modeling/model/sherpa-onnx-streaming-zipformer-korean-2024-06-16\")\n",
    "\n",
    "def pick_model_files(model_dir: Path):\n",
    "    def pick(prefix: str):\n",
    "        int8 = sorted(model_dir.glob(f\"{prefix}-epoch-*.int8.onnx\"))\n",
    "        fp32 = sorted(p for p in model_dir.glob(f\"{prefix}-epoch-*.onnx\") if \".int8.\" not in p.name)\n",
    "        return (int8[-1] if int8 else (fp32[-1] if fp32 else None))\n",
    "    tokens = model_dir / \"tokens.txt\"\n",
    "    enc = pick(\"encoder\"); dec = pick(\"decoder\"); join = pick(\"joiner\")\n",
    "    assert tokens.exists(), \"tokens.txt 없음\"\n",
    "    assert enc and dec and join, \"encoder/decoder/joiner onnx를 찾지 못함\"\n",
    "    return tokens, enc, dec, join\n",
    "\n",
    "TOKENS, ENC, DEC, JOIN = pick_model_files(MODEL_DIR)\n",
    "\n",
    "recognizer = sherpa_onnx.OnlineRecognizer.from_transducer(\n",
    "    tokens=str(TOKENS),\n",
    "    encoder=str(ENC),\n",
    "    decoder=str(DEC),\n",
    "    joiner=str(JOIN),\n",
    "    decoding_method=\"greedy_search\",\n",
    "    num_threads=2,\n",
    "    provider=\"cpu\",   # 가능하면 'coreml'도 시도 가능 (onnxruntime에서 CoreML EP가 보일 때)\n",
    ")\n",
    "\n",
    "print(\"✅ 모델 로드 완료\")\n",
    "print(\" - tokens :\", TOKENS.name)\n",
    "print(\" - encoder:\", ENC.name)\n",
    "print(\" - decoder:\", DEC.name)\n",
    "print(\" - joiner :\", JOIN.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4e175ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re, time, unicodedata, csv\n",
    "from pathlib import Path\n",
    "\n",
    "def u_nfc(s: str) -> str:\n",
    "    return unicodedata.normalize(\"NFC\", s)\n",
    "\n",
    "# 간단 정규화: 한글 보존, 구두점 제거, 공백 정리\n",
    "import re\n",
    "_re_punct = re.compile(r\"[^\\w\\s]\", flags=re.UNICODE)\n",
    "_re_ws = re.compile(r\"\\s+\")\n",
    "\n",
    "def normalize_for_wer(s: str) -> str:\n",
    "    s = u_nfc(s).lower()\n",
    "    s = _re_punct.sub(\" \", s)\n",
    "    s = _re_ws.sub(\" \", s).strip()\n",
    "    return s\n",
    "\n",
    "def normalize_for_cer(s: str) -> str:\n",
    "    s = normalize_for_wer(s)\n",
    "    s = s.replace(\" \", \"\")\n",
    "    return s\n",
    "\n",
    "def levenshtein(seq_a, seq_b):\n",
    "    n, m = len(seq_a), len(seq_b)\n",
    "    if n == 0: return m\n",
    "    if m == 0: return n\n",
    "    dp = list(range(m+1))\n",
    "    for i in range(1, n+1):\n",
    "        prev, dp[0] = dp[0], i\n",
    "        for j in range(1, m+1):\n",
    "            cur = dp[j]\n",
    "            cost = 0 if seq_a[i-1] == seq_b[j-1] else 1\n",
    "            dp[j] = min(dp[j] + 1, dp[j-1] + 1, prev + cost)\n",
    "            prev = cur\n",
    "    return dp[m]\n",
    "\n",
    "def cer_score(ref: str, hyp: str):\n",
    "    r = normalize_for_cer(ref)\n",
    "    h = normalize_for_cer(hyp)\n",
    "    if len(r) == 0: return 0.0, 0, 0\n",
    "    dist = levenshtein(r, h)\n",
    "    return dist / len(r), dist, len(r)\n",
    "\n",
    "def wer_score(ref: str, hyp: str):\n",
    "    r = normalize_for_wer(ref).split()\n",
    "    h = normalize_for_wer(hyp).split()\n",
    "    if len(r) == 0: return 0.0, 0, 0\n",
    "    dist = levenshtein(r, h)\n",
    "    return dist / len(r), dist, len(r)\n",
    "\n",
    "def load_trn(trn_path) -> dict:\n",
    "    \"\"\"\n",
    "    TRN 라인 예시 여러 형태를 모두 허용:\n",
    "      1) '문장 텍스트 ... (KsponSpeech_E00001)'\n",
    "      2) 'KsponSpeech_E00001 문장 텍스트 ...'\n",
    "      3) 'KsponSpeech_E00001.wav\\t문장 텍스트 ...'\n",
    "    반환: { 'KsponSpeech_E00001': '문장 텍스트 ...', ... }\n",
    "    \"\"\"\n",
    "    trn_path = Path(trn_path)\n",
    "    mapping = {}\n",
    "    with trn_path.open(\"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "\n",
    "            # 케이스 1) 마지막 괄호의 ID\n",
    "            m = re.search(r\"\\(([^)]+)\\)\\s*$\", line)\n",
    "            if m:\n",
    "                utt = m.group(1)\n",
    "                text = line[:m.start()].strip()\n",
    "            else:\n",
    "                # 케이스 2/3) <utt>[.wav] <sep> <text>\n",
    "                parts = re.split(r\"[\\t ]+\", line, maxsplit=1)\n",
    "                if len(parts) == 2:\n",
    "                    utt, text = parts[0], parts[1]\n",
    "                else:\n",
    "                    # 파싱 실패 시 스킵\n",
    "                    continue\n",
    "\n",
    "            utt = os.path.basename(utt)\n",
    "            utt = os.path.splitext(utt)[0]  # .wav 제거\n",
    "            mapping[utt] = text\n",
    "    return mapping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "185810b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import soundfile as sf\n",
    "import numpy as np\n",
    "\n",
    "def resample_to_16k(wave: np.ndarray, sr: int) -> np.ndarray:\n",
    "    if sr == 16000:\n",
    "        return wave.astype(\"float32\", copy=False)\n",
    "    # 의존성 없이 간단 선형보간 리샘플\n",
    "    import numpy as np\n",
    "    x = np.arange(len(wave))\n",
    "    new_len = int(round(len(wave) * 16000 / sr))\n",
    "    new_x = np.linspace(0, len(wave)-1, new_len)\n",
    "    out = np.interp(new_x, x, wave).astype(\"float32\")\n",
    "    return out\n",
    "\n",
    "def decode_once(audio: np.ndarray, sr: int) -> str:\n",
    "    if audio.ndim == 2:\n",
    "        audio = audio.mean(axis=1)\n",
    "    if sr != 16000:\n",
    "        audio = resample_to_16k(audio, sr)\n",
    "        sr = 16000\n",
    "    stream = recognizer.create_stream()\n",
    "    stream.accept_waveform(sr, audio.astype(\"float32\", copy=False))\n",
    "    stream.input_finished()\n",
    "    while recognizer.is_ready(stream):\n",
    "        recognizer.decode_stream(stream)\n",
    "    res = recognizer.get_result(stream)\n",
    "    # sherpa-onnx 1.12.10은 str을 반환\n",
    "    return res if isinstance(res, str) else (res.text if hasattr(res, \"text\") else str(res))\n",
    "    \n",
    "def evaluate_split(wav_dir, trn_path, csv_out=None):\n",
    "    from pathlib import Path\n",
    "    wav_dir  = Path(wav_dir)\n",
    "    trn_path = Path(trn_path)\n",
    "    csv_out  = Path(csv_out) if csv_out is not None else None\n",
    "    refs = load_trn(trn_path)\n",
    "    wavs = sorted(wav_dir.glob(\"*.wav\"))\n",
    "    assert wavs, f\"WAV 없음: {wav_dir}\"\n",
    "    print(f\"Files: {len(wavs)} | TRN keys: {len(refs)}\")\n",
    "\n",
    "    rows = []\n",
    "    tot_cdist = tot_cN = 0\n",
    "    tot_wdist = tot_wN = 0\n",
    "    tot_secs  = tot_infer = 0.0\n",
    "    miss_ref = 0\n",
    "\n",
    "    for i, wav in enumerate(wavs, 1):\n",
    "        utt = wav.stem\n",
    "        ref = refs.get(utt)\n",
    "        if ref is None:\n",
    "            miss_ref += 1\n",
    "            continue\n",
    "\n",
    "        audio, sr = sf.read(str(wav), dtype=\"float32\", always_2d=False)\n",
    "        dur = float(len(audio) / sr)\n",
    "        t0 = time.perf_counter()\n",
    "        hyp = decode_once(audio, sr)\n",
    "        t1 = time.perf_counter()\n",
    "        infer = t1 - t0\n",
    "        rtf = infer / max(dur, 1e-9)\n",
    "\n",
    "        cer, cdist, cN = cer_score(ref, hyp)\n",
    "        wer, wdist, wN = wer_score(ref, hyp)\n",
    "\n",
    "        rows.append({\n",
    "            \"utt\": utt,\n",
    "            \"dur_s\": round(dur, 3),\n",
    "            \"infer_s\": round(infer, 3),\n",
    "            \"rtf\": round(rtf, 3),\n",
    "            \"CER\": round(cer, 4),\n",
    "            \"WER\": round(wer, 4),\n",
    "            \"ref\": ref,\n",
    "            \"hyp\": hyp,\n",
    "        })\n",
    "\n",
    "        tot_cdist += cdist; tot_cN += cN\n",
    "        tot_wdist += wdist; tot_wN += wN\n",
    "        tot_secs  += dur;   tot_infer += infer\n",
    "\n",
    "        if i % 20 == 0:\n",
    "            print(f\"[{i}/{len(wavs)}] RTF~{rtf:.2f} | CER~{cer:.3f} | WER~{wer:.3f}\")\n",
    "\n",
    "    overall_cer = (tot_cdist / tot_cN) if tot_cN else 0.0\n",
    "    overall_wer = (tot_wdist / tot_wN) if tot_wN else 0.0\n",
    "    avg_rtf     = (tot_infer / tot_secs) if tot_secs else 0.0\n",
    "    print(\"\\n=== Summary ===\")\n",
    "    print(f\"Files scored     : {len(rows)} (missing refs: {miss_ref})\")\n",
    "    print(f\"Total audio (s)  : {tot_secs:.1f}\")\n",
    "    print(f\"Total infer (s)  : {tot_infer:.1f}\")\n",
    "    print(f\"Avg RTF          : {avg_rtf:.3f}\")\n",
    "    print(f\"CER (char)       : {overall_cer:.4f}\")\n",
    "    print(f\"WER (word)       : {overall_wer:.4f}\")\n",
    "\n",
    "    if csv_out:\n",
    "        csv_out.parent.mkdir(parents=True, exist_ok=True)\n",
    "        with open(csv_out, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "            w = csv.DictWriter(f, fieldnames=list(rows[0].keys()))\n",
    "            w.writeheader()\n",
    "            w.writerows(rows)\n",
    "        print(f\"Saved: {csv_out}\")\n",
    "\n",
    "    # 상위 5개 오차 큰 샘플(참고)\n",
    "    rows_sorted = sorted(rows, key=lambda r: (-r[\"CER\"], -r[\"WER\"], -r[\"rtf\"]))\n",
    "    print(\"\\nTop-5 by CER:\")\n",
    "    for r in rows_sorted[:5]:\n",
    "        print(f\"- {r['utt']} | CER {r['CER']:.3f} WER {r['WER']:.3f} RTF {r['rtf']:.2f} | ref: {r['ref']} | hyp: {r['hyp']}\")\n",
    "    return {\n",
    "        \"rows\": rows,\n",
    "        \"summary\": dict(files=len(rows), miss_ref=miss_ref, total_audio_s=tot_secs,\n",
    "                        total_infer_s=tot_infer, avg_rtf=avg_rtf,\n",
    "                        cer=overall_cer, wer=overall_wer)\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "24e92d20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files: 3000 | TRN keys: 3000\n",
      "[20/3000] RTF~0.05 | CER~0.000 | WER~0.105\n",
      "[40/3000] RTF~0.04 | CER~0.545 | WER~0.600\n",
      "[60/3000] RTF~0.04 | CER~0.143 | WER~0.333\n",
      "[80/3000] RTF~0.04 | CER~0.714 | WER~0.750\n",
      "[100/3000] RTF~0.05 | CER~0.322 | WER~0.519\n",
      "[120/3000] RTF~0.09 | CER~0.750 | WER~0.500\n",
      "[140/3000] RTF~0.05 | CER~0.115 | WER~0.231\n",
      "[160/3000] RTF~0.06 | CER~0.182 | WER~0.500\n",
      "[180/3000] RTF~0.04 | CER~0.500 | WER~0.400\n",
      "[200/3000] RTF~0.07 | CER~0.000 | WER~0.667\n",
      "[220/3000] RTF~0.04 | CER~1.000 | WER~1.000\n",
      "[240/3000] RTF~0.06 | CER~0.085 | WER~0.167\n",
      "[260/3000] RTF~0.03 | CER~0.667 | WER~0.500\n",
      "[280/3000] RTF~0.06 | CER~0.182 | WER~0.300\n",
      "[300/3000] RTF~0.04 | CER~0.667 | WER~0.500\n",
      "[320/3000] RTF~0.05 | CER~0.000 | WER~0.000\n",
      "[340/3000] RTF~0.05 | CER~0.200 | WER~0.500\n",
      "[360/3000] RTF~0.06 | CER~0.184 | WER~0.412\n",
      "[380/3000] RTF~0.04 | CER~0.667 | WER~0.667\n",
      "[400/3000] RTF~0.07 | CER~0.231 | WER~0.400\n",
      "[420/3000] RTF~0.14 | CER~0.200 | WER~0.200\n",
      "[440/3000] RTF~0.06 | CER~0.021 | WER~0.056\n",
      "[460/3000] RTF~0.05 | CER~0.400 | WER~0.286\n",
      "[480/3000] RTF~0.06 | CER~0.244 | WER~0.500\n",
      "[500/3000] RTF~0.05 | CER~0.750 | WER~1.000\n",
      "[520/3000] RTF~0.04 | CER~1.000 | WER~1.000\n",
      "[540/3000] RTF~0.06 | CER~0.000 | WER~0.000\n",
      "[560/3000] RTF~0.06 | CER~0.429 | WER~0.600\n",
      "[580/3000] RTF~0.05 | CER~0.156 | WER~0.227\n",
      "[600/3000] RTF~0.05 | CER~0.167 | WER~0.375\n",
      "[620/3000] RTF~0.05 | CER~0.333 | WER~0.500\n",
      "[640/3000] RTF~0.05 | CER~0.062 | WER~0.125\n",
      "[660/3000] RTF~0.09 | CER~0.000 | WER~0.000\n",
      "[680/3000] RTF~0.66 | CER~0.282 | WER~0.444\n",
      "[700/3000] RTF~0.08 | CER~0.048 | WER~0.286\n",
      "[720/3000] RTF~0.11 | CER~0.333 | WER~0.400\n",
      "[740/3000] RTF~0.05 | CER~0.067 | WER~0.143\n",
      "[760/3000] RTF~0.10 | CER~0.438 | WER~0.333\n",
      "[780/3000] RTF~0.05 | CER~0.222 | WER~0.250\n",
      "[800/3000] RTF~0.05 | CER~1.000 | WER~1.000\n",
      "[820/3000] RTF~0.06 | CER~0.161 | WER~0.231\n",
      "[840/3000] RTF~0.04 | CER~0.500 | WER~0.667\n",
      "[860/3000] RTF~0.07 | CER~0.140 | WER~0.519\n",
      "[880/3000] RTF~0.03 | CER~0.857 | WER~1.000\n",
      "[900/3000] RTF~0.06 | CER~0.375 | WER~0.500\n",
      "[920/3000] RTF~0.05 | CER~0.000 | WER~0.000\n",
      "[940/3000] RTF~0.05 | CER~0.714 | WER~0.750\n",
      "[960/3000] RTF~0.06 | CER~0.105 | WER~0.273\n",
      "[980/3000] RTF~0.08 | CER~0.778 | WER~0.800\n",
      "[1000/3000] RTF~0.04 | CER~0.222 | WER~0.250\n",
      "[1020/3000] RTF~0.06 | CER~0.160 | WER~0.167\n",
      "[1040/3000] RTF~0.05 | CER~0.000 | WER~0.000\n",
      "[1060/3000] RTF~0.05 | CER~0.417 | WER~0.400\n",
      "[1080/3000] RTF~0.06 | CER~0.091 | WER~0.300\n",
      "[1100/3000] RTF~0.05 | CER~0.600 | WER~0.500\n",
      "[1120/3000] RTF~0.05 | CER~0.059 | WER~0.143\n",
      "[1140/3000] RTF~0.06 | CER~0.000 | WER~0.000\n",
      "[1160/3000] RTF~0.06 | CER~0.267 | WER~0.444\n",
      "[1180/3000] RTF~0.05 | CER~0.550 | WER~0.800\n",
      "[1200/3000] RTF~0.11 | CER~0.224 | WER~0.250\n",
      "[1220/3000] RTF~0.06 | CER~0.070 | WER~0.125\n",
      "[1240/3000] RTF~0.06 | CER~0.087 | WER~0.105\n",
      "[1260/3000] RTF~0.06 | CER~0.179 | WER~0.421\n",
      "[1280/3000] RTF~0.06 | CER~0.062 | WER~0.111\n",
      "[1300/3000] RTF~0.77 | CER~0.333 | WER~0.500\n",
      "[1320/3000] RTF~0.06 | CER~0.500 | WER~0.833\n",
      "[1340/3000] RTF~0.06 | CER~0.000 | WER~0.118\n",
      "[1360/3000] RTF~0.05 | CER~0.000 | WER~0.000\n",
      "[1380/3000] RTF~0.06 | CER~0.079 | WER~0.294\n",
      "[1400/3000] RTF~0.09 | CER~0.000 | WER~0.000\n",
      "[1420/3000] RTF~0.06 | CER~0.200 | WER~0.500\n",
      "[1440/3000] RTF~0.07 | CER~0.238 | WER~0.368\n",
      "[1460/3000] RTF~0.06 | CER~0.000 | WER~0.000\n",
      "[1480/3000] RTF~0.05 | CER~0.222 | WER~0.250\n",
      "[1500/3000] RTF~0.05 | CER~0.250 | WER~0.250\n",
      "[1520/3000] RTF~0.08 | CER~0.500 | WER~0.833\n",
      "[1540/3000] RTF~0.06 | CER~0.522 | WER~1.000\n",
      "[1560/3000] RTF~0.06 | CER~0.667 | WER~0.500\n",
      "[1580/3000] RTF~0.04 | CER~1.000 | WER~1.000\n",
      "[1600/3000] RTF~0.07 | CER~0.200 | WER~0.250\n",
      "[1620/3000] RTF~0.07 | CER~0.200 | WER~2.000\n",
      "[1640/3000] RTF~0.13 | CER~0.000 | WER~0.000\n",
      "[1660/3000] RTF~0.06 | CER~0.286 | WER~0.667\n",
      "[1680/3000] RTF~0.06 | CER~0.500 | WER~0.667\n",
      "[1700/3000] RTF~0.05 | CER~0.333 | WER~1.000\n",
      "[1720/3000] RTF~0.06 | CER~0.083 | WER~0.167\n",
      "[1740/3000] RTF~0.09 | CER~0.129 | WER~0.364\n",
      "[1760/3000] RTF~0.09 | CER~0.400 | WER~0.500\n",
      "[1780/3000] RTF~0.06 | CER~0.321 | WER~0.333\n",
      "[1800/3000] RTF~0.13 | CER~0.341 | WER~0.438\n",
      "[1820/3000] RTF~0.06 | CER~0.250 | WER~1.000\n",
      "[1840/3000] RTF~0.07 | CER~0.167 | WER~0.500\n",
      "[1860/3000] RTF~0.13 | CER~0.104 | WER~0.316\n",
      "[1880/3000] RTF~0.06 | CER~0.250 | WER~0.400\n",
      "[1900/3000] RTF~0.10 | CER~0.357 | WER~0.500\n",
      "[1920/3000] RTF~0.25 | CER~0.077 | WER~0.857\n",
      "[1940/3000] RTF~0.06 | CER~0.231 | WER~0.500\n",
      "[1960/3000] RTF~0.08 | CER~0.444 | WER~0.500\n",
      "[1980/3000] RTF~0.08 | CER~0.182 | WER~0.333\n",
      "[2000/3000] RTF~0.03 | CER~1.000 | WER~1.000\n",
      "[2020/3000] RTF~0.08 | CER~0.000 | WER~0.000\n",
      "[2040/3000] RTF~0.11 | CER~0.364 | WER~0.714\n",
      "[2060/3000] RTF~0.11 | CER~0.056 | WER~0.111\n",
      "[2080/3000] RTF~0.08 | CER~0.429 | WER~0.667\n",
      "[2100/3000] RTF~0.09 | CER~0.333 | WER~0.700\n",
      "[2120/3000] RTF~0.07 | CER~0.292 | WER~0.571\n",
      "[2140/3000] RTF~0.07 | CER~0.077 | WER~0.250\n",
      "[2160/3000] RTF~0.08 | CER~0.158 | WER~0.111\n",
      "[2180/3000] RTF~0.05 | CER~0.750 | WER~0.500\n",
      "[2200/3000] RTF~0.18 | CER~0.129 | WER~0.182\n",
      "[2220/3000] RTF~0.05 | CER~0.667 | WER~0.667\n",
      "[2240/3000] RTF~0.06 | CER~0.750 | WER~0.500\n",
      "[2260/3000] RTF~0.05 | CER~1.000 | WER~1.000\n",
      "[2280/3000] RTF~0.09 | CER~0.286 | WER~0.444\n",
      "[2300/3000] RTF~0.07 | CER~0.400 | WER~0.600\n",
      "[2320/3000] RTF~0.07 | CER~0.500 | WER~0.800\n",
      "[2340/3000] RTF~0.03 | CER~1.000 | WER~1.000\n",
      "[2360/3000] RTF~0.07 | CER~0.000 | WER~0.000\n",
      "[2380/3000] RTF~0.07 | CER~0.150 | WER~0.250\n",
      "[2400/3000] RTF~0.07 | CER~0.217 | WER~0.556\n",
      "[2420/3000] RTF~0.09 | CER~0.154 | WER~0.250\n",
      "[2440/3000] RTF~0.06 | CER~0.211 | WER~0.429\n",
      "[2460/3000] RTF~0.08 | CER~0.500 | WER~0.750\n",
      "[2480/3000] RTF~0.09 | CER~0.000 | WER~0.000\n",
      "[2500/3000] RTF~0.17 | CER~0.160 | WER~0.207\n",
      "[2520/3000] RTF~0.07 | CER~0.172 | WER~0.333\n",
      "[2540/3000] RTF~0.07 | CER~0.200 | WER~0.500\n",
      "[2560/3000] RTF~0.05 | CER~1.000 | WER~1.000\n",
      "[2580/3000] RTF~0.06 | CER~0.636 | WER~1.000\n",
      "[2600/3000] RTF~0.08 | CER~0.022 | WER~0.062\n",
      "[2620/3000] RTF~0.05 | CER~0.800 | WER~1.000\n",
      "[2640/3000] RTF~0.12 | CER~0.192 | WER~0.417\n",
      "[2660/3000] RTF~0.08 | CER~0.000 | WER~0.000\n",
      "[2680/3000] RTF~0.06 | CER~0.667 | WER~0.500\n",
      "[2700/3000] RTF~0.07 | CER~0.190 | WER~0.400\n",
      "[2720/3000] RTF~0.08 | CER~0.049 | WER~0.188\n",
      "[2740/3000] RTF~0.06 | CER~0.182 | WER~0.200\n",
      "[2760/3000] RTF~0.06 | CER~0.600 | WER~0.500\n",
      "[2780/3000] RTF~0.07 | CER~0.000 | WER~0.000\n",
      "[2800/3000] RTF~0.11 | CER~0.306 | WER~0.357\n",
      "[2820/3000] RTF~0.07 | CER~0.158 | WER~0.444\n",
      "[2840/3000] RTF~0.09 | CER~0.000 | WER~1.000\n",
      "[2860/3000] RTF~0.08 | CER~0.081 | WER~0.143\n",
      "[2880/3000] RTF~0.06 | CER~0.000 | WER~0.000\n",
      "[2900/3000] RTF~0.17 | CER~0.278 | WER~0.375\n",
      "[2920/3000] RTF~0.20 | CER~0.154 | WER~0.429\n",
      "[2940/3000] RTF~0.07 | CER~0.800 | WER~1.000\n",
      "[2960/3000] RTF~0.07 | CER~0.333 | WER~0.500\n",
      "[2980/3000] RTF~0.08 | CER~0.174 | WER~0.222\n",
      "[3000/3000] RTF~0.06 | CER~0.400 | WER~0.667\n",
      "\n",
      "=== Summary ===\n",
      "Files scored     : 2981 (missing refs: 19)\n",
      "Total audio (s)  : 9479.1\n",
      "Total infer (s)  : 736.4\n",
      "Avg RTF          : 0.078\n",
      "CER (char)       : 0.2161\n",
      "WER (word)       : 0.3628\n",
      "Saved: results_eval/eval_clean_results.csv\n",
      "\n",
      "Top-5 by CER:\n",
      "- KsponSpeech_E02695 | CER 1.000 WER 1.000 RTF 0.16 | ref: :: 없더라. | hyp: \n",
      "- KsponSpeech_E02868 | CER 1.000 WER 1.000 RTF 0.15 | ref: :: 아니야 | hyp: \n",
      "- KsponSpeech_E00677 | CER 1.000 WER 1.000 RTF 0.14 | ref: :: 그러면은 | hyp: \n",
      "- KsponSpeech_E00609 | CER 1.000 WER 1.000 RTF 0.14 | ref: :: b/ 아니야. | hyp: \n",
      "- KsponSpeech_E00685 | CER 1.000 WER 1.000 RTF 0.14 | ref: :: 반전이 있어. | hyp: 단\n"
     ]
    }
   ],
   "source": [
    "# 데이터 루트 지정 (네 스샷 구조 기준)\n",
    "DATA_ROOT = Path(\"data\")  # 필요하면 절대경로로 바꿔도 됨\n",
    "\n",
    "# 1) eval_clean\n",
    "wav_dir = \"/Users/leejeje/Desktop/DSL/25-1/Modeling/data/KsponSpeech_eval/eval_clean\"\n",
    "trn_path = \"/Users/leejeje/Desktop/DSL/25-1/Modeling/data/KsponSpeech_scripts/eval_clean.trn\"\n",
    "out_csv = Path(\"results_eval\") / \"eval_clean_results.csv\"\n",
    "res_clean = evaluate_split(wav_dir, trn_path, csv_out=out_csv)\n",
    "\n",
    "# # 2) (선택) eval_other\n",
    "# wav_dir = DATA_ROOT / \"KsponSpeech_eval\" / \"eval_other\"\n",
    "# trn_path = DATA_ROOT / \"KsponSpeech_scripts\" / \"eval_other.trn\"\n",
    "# out_csv = Path(\"results_eval\") / \"eval_other_results.csv\"\n",
    "# res_other = evaluate_split(wav_dir, trn_path, csv_out=out_csv)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "asr-korean",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
